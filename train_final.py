import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
import time

print("ğŸš€ è®­ç»ƒè„šæœ¬å¯åŠ¨")

try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False
    print("è­¦å‘Šï¼šæœªæ‰¾åˆ°cv2æ¨¡å—ï¼Œå°†ä½¿ç”¨PILè¿›è¡Œå›¾åƒå¤„ç†")

try:
    from dyunet import DyUNet
    print("æˆåŠŸå¯¼å…¥dyunetæ¨¡å—")
except ImportError:
    print("é”™è¯¯ï¼šæœªæ‰¾åˆ°dyunetæ¨¡å—")

    class DyUNet(nn.Module):
        def __init__(self, in_channels, out_channels, base_channels, g):
            super().__init__()
            self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)

        def forward(self, x):
            return self.conv(x)


class SegmentationDataset(Dataset):
    def __init__(self, image_dir, mask_dir, image_transform=None, mask_transform=None):
        self.image_dir = image_dir
        self.mask_dir = mask_dir
        self.image_transform = image_transform
        self.mask_transform = mask_transform
        self.image_files = sorted(os.listdir(image_dir))
        self.mask_files = sorted(os.listdir(mask_dir))

        assert len(self.image_files) == len(self.mask_files), "å›¾åƒå’Œæ©ç æ–‡ä»¶æ•°é‡ä¸åŒ¹é…"
        for img, msk in zip(self.image_files, self.mask_files):
            img_name = os.path.splitext(img)[0]
        msk_name = os.path.splitext(msk)[0].replace('_mask', '')
        assert img_name == msk_name, f"æ–‡ä»¶ä¸åŒ¹é…: {img} vs {msk}"

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        img_path = os.path.join(self.image_dir, self.image_files[idx])
        mask_path = os.path.join(self.mask_dir, self.mask_files[idx])

        image = Image.open(img_path).convert('RGB')
        mask = Image.open(mask_path).convert('L')

        if self.image_transform:
            image = self.image_transform(image)
        if self.mask_transform:
            mask = self.mask_transform(mask)

        return image, mask


class DiceBCELoss(nn.Module):
    def __init__(self, smooth=1e-5):
        super(DiceBCELoss, self).__init__()
        self.smooth = smooth
        self.bce = nn.BCEWithLogitsLoss()

    def forward(self, pred, target):
        pred = torch.sigmoid(pred)
        intersection = (pred * target).sum()
        dice = (2. * intersection + self.smooth) / (pred.sum() + target.sum() + self.smooth)
        bce = self.bce(pred, target)
        return bce + (1 - dice)


def main():
    torch.manual_seed(42)
    np.random.seed(42)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")

    base_data_path = "/root/autodl-tmp/dyunet_data"
    print(f"æ•°æ®è·¯å¾„: {base_data_path}")

    image_transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225])
    ])

    mask_transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.ToTensor()
    ])

    # ğŸ› ï¸ ä¿®æ”¹ä¸ºä½ çš„çœŸå®è·¯å¾„
    train_dataset = SegmentationDataset(
        image_dir=os.path.join(base_data_path, 'imgs'),
        mask_dir=os.path.join(base_data_path, 'masks'),
        image_transform=image_transform,
        mask_transform=mask_transform
    )

    val_dataset = train_dataset  # âš ï¸ æš‚æ—¶ä½¿ç”¨ç›¸åŒæ•°æ®é›†ä½œä¸ºéªŒè¯é›†

    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)
    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=4)

    model = DyUNet(in_channels=3, out_channels=1).to(device)
    print(f"æ¨¡å‹ç»“æ„:\n{model}")

    criterion = DiceBCELoss()
    optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)

    os.makedirs("output", exist_ok=True)
    print("è¾“å‡ºç›®å½•å·²åˆ›å»º")

    def predict(model, image_path, image_transform, device):
        image = Image.open(image_path).convert('RGB')
        original_size = image.size
        image_tensor = image_transform(image).unsqueeze(0).to(device)

        model.eval()
        with torch.no_grad():
            output = model(image_tensor)
            probs = torch.sigmoid(output)
            predicted_mask = (probs > 0.5).float()

        predicted_mask = predicted_mask.squeeze().cpu().numpy()
        predicted_mask = (predicted_mask * 255).astype(np.uint8)

        if CV2_AVAILABLE:
            return cv2.resize(predicted_mask, original_size, interpolation=cv2.INTER_NEAREST)
        else:
            return Image.fromarray(predicted_mask).resize(original_size, Image.NEAREST)

    def visualize(image_path, mask_path, prediction, save_path):
        image = Image.open(image_path).convert('RGB')
        true_mask = Image.open(mask_path).convert('L')

        plt.figure(figsize=(15, 10))
        plt.subplot(1, 3, 1)
        plt.imshow(image)
        plt.title('åŸå§‹å›¾åƒ')
        plt.axis('off')

        plt.subplot(1, 3, 2)
        plt.imshow(true_mask, cmap='gray')
        plt.title('çœŸå®æ©ç ')
        plt.axis('off')

        plt.subplot(1, 3, 3)
        plt.imshow(prediction, cmap='gray')
        plt.title('é¢„æµ‹ç»“æœ')
        plt.axis('off')

        plt.tight_layout()
        plt.savefig(save_path)
        plt.close()

    train_losses = []
    val_losses = []
    best_val_loss = float('inf')

    for epoch in range(50):
        print(f"\nEpoch {epoch + 1}/50")
        start_time = time.time()

        model.train()
        train_loss = 0.0
        for images, masks in tqdm(train_loader, desc="Training"):
            images = images.to(device)
            masks = masks.to(device)

            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, masks)
            loss.backward()
            optimizer.step()
            train_loss += loss.item()

        avg_train_loss = train_loss / len(train_loader)
        train_losses.append(avg_train_loss)

        model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for images, masks in tqdm(val_loader, desc="Validation"):
                images = images.to(device)
                masks = masks.to(device)

                outputs = model(images)
                loss = criterion(outputs, masks)
                val_loss += loss.item()

        avg_val_loss = val_loss / len(val_loader)
        val_losses.append(avg_val_loss)

        scheduler.step(avg_val_loss)

        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            torch.save(model.state_dict(), 'output/best_model.pth')
            print(f"ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ŒéªŒè¯æŸå¤±: {avg_val_loss:.4f}")

        epoch_time = time.time() - start_time
        print(f"è®­ç»ƒæŸå¤±: {avg_train_loss:.4f}, éªŒè¯æŸå¤±: {avg_val_loss:.4f}, è€—æ—¶: {epoch_time:.2f}s")

        checkpoint = {
            'epoch': epoch + 1,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'scheduler_state_dict': scheduler.state_dict(),
            'train_loss': train_losses,
            'val_loss': val_losses,
            'best_val_loss': best_val_loss
        }
        torch.save(checkpoint, 'output/checkpoint.pth')

        plt.figure(figsize=(10, 5))
        plt.plot(train_losses, label='è®­ç»ƒæŸå¤±')
        plt.plot(val_losses, label='éªŒè¯æŸå¤±')
        plt.xlabel('è½®æ¬¡')
        plt.ylabel('æŸå¤±')
        plt.title('è®­ç»ƒå’ŒéªŒè¯æŸå¤±')
        plt.legend()
        plt.savefig('output/loss_curve.png')
        plt.close()

        if (epoch + 1) % 5 == 0:
            sample_image_path = os.path.join(base_data_path, 'imgs', os.listdir(os.path.join(base_data_path, 'imgs'))[0])
            sample_mask_path = os.path.join(base_data_path, 'masks', os.listdir(os.path.join(base_data_path, 'masks'))[0])

            prediction = predict(model, sample_image_path, image_transform, device)
            if isinstance(prediction, Image.Image):
                prediction = np.array(prediction)

            visualize(sample_image_path, sample_mask_path, prediction,
                      f'output/prediction_epoch_{epoch + 1}.png')
            print(f"ä¿å­˜é¢„æµ‹ç»“æœ: output/prediction_epoch_{epoch + 1}.png")

    print("è®­ç»ƒå®Œæˆï¼")
    print(f"æœ€ä½³æ¨¡å‹å·²ä¿å­˜è‡³: output/best_model.pth")


if __name__ == "__main__":
    main()
